{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92eea108-3ee3-4c0b-a0f7-1e1c4d899ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "One-Hot-Kodierung mit pandas get_dummies: \n",
      "    kategorie_Bücher  kategorie_Elektronik  kategorie_Kleidung\n",
      "0                  0                     1                   0\n",
      "1                  0                     0                   1\n",
      "2                  1                     0                   0\n",
      "3                  0                     1                   0\n",
      "4                  0                     1                   0\n",
      "5                  1                     0                   0\n",
      "6                  0                     0                   1\n",
      "7                  1                     0                   0\n",
      "8                  0                     1                   0\n",
      "9                  0                     0                   1\n",
      "10                 1                     0                   0\n",
      "11                 0                     1                   0\n",
      "12                 1                     0                   0\n",
      "13                 0                     1                   0\n",
      "14                 0                     0                   1\n",
      "15                 0                     0                   1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('products.csv', encoding='UTF-8')\n",
    "df_dummies = pd.get_dummies(df, columns=['kategorie']).astype(int)\n",
    "\n",
    "#ergebnis anzeigen\n",
    "print('\\nOne-Hot-Kodierung mit pandas get_dummies: ')\n",
    "print(df_dummies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc471d06-7bc8-42eb-8ebe-a4d578ce7ad2",
   "metadata": {},
   "source": [
    "## Converting Text to Featrures II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8663a544-1bd2-4135-86ce-29720d45cbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.9/site-packages (from scikit-learn) (2.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.9/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.9/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.9/site-packages (from scikit-learn) (1.4.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb964378-276f-4935-a3b6-db215bf623d7",
   "metadata": {},
   "source": [
    "#### 4.2.1 Textklassifizierung am Beispiel Spam/Ham "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91099dce-49e3-433e-9d87-f7a916643952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8598838e-393c-480b-8244-7ef487368700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vokabular {'nlp': 8, 'unlocks': 12, 'insights': 5, 'evolving': 3, 'ml': 7, 'learns': 6, 'patterns': 9, 'applications': 1, 'abound': 0, 'preprocessing': 10, 'crucial': 2, 'for': 4, 'understanding': 11}\n",
      "Vokabular {'nlp': 8, 'unlocks': 12, 'insights': 5, 'evolving': 3, 'ml': 7, 'learns': 6, 'patterns': 9, 'applications': 1, 'abound': 0, 'preprocessing': 10, 'crucial': 2, 'for': 4, 'understanding': 11}\n",
      "Bag of Words\n",
      " [[0 0 0 1 0 1 0 0 2 0 0 0 1]\n",
      " [1 1 0 0 0 0 1 2 0 1 0 0 0]\n",
      " [0 0 1 0 1 0 0 0 2 0 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "text = [     \n",
    "    \"NLP unlocks insights, NLP evolving.\",     \n",
    "    \"ML learns patterns; ML applications abound.\",     \n",
    "    \"NLP preprocessing crucial for NLP understanding.\" \n",
    "] \n",
    "\n",
    "vectorizer = CountVectorizer() \n",
    "\n",
    "# Erstellt das Vokabular aus den Textdaten \n",
    "X=vectorizer.fit(text) \n",
    "\n",
    "print(\"Vokabular\", vectorizer.vocabulary_)\n",
    "\n",
    "# Features ausgeben \n",
    "print(\"Vokabular\", vectorizer.vocabulary_) \n",
    "\n",
    "# Text basierend auf Vokabular vektorisieren. Ergebnis ist BoW \n",
    "X=vectorizer.transform(text) \n",
    "\n",
    "print(\"Bag of Words\\n\", X.toarray()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73e8221a-4113-4299-9b76-4b154dc0f865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target                                            message\n",
       "0       ham  Go until jurong point, crazy.. Available only ...\n",
       "1       ham                      Ok lar... Joking wif u oni...\n",
       "2      spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       ham  U dun say so early hor... U c already then say...\n",
       "4       ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...     ...                                                ...\n",
       "5567   spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568    ham              Will Ì_ b going to esplanade fr home?\n",
       "5569    ham  Pity, * was in mood for that. So...any other s...\n",
       "5570    ham  The guy did some bitching but I acted like i'd...\n",
       "5571    ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam = pd.read_csv(\"spam.csv\", encoding='latin1')\n",
    "spam = spam[[\"v1\",\"v2\"]]\n",
    "spam.columns = ['target', 'message']\n",
    "spam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4398ba69-4186-4dd9-867c-4f2b79fafc3b",
   "metadata": {},
   "source": [
    "#### Step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6881491f-6b3e-4a0d-ab59-3abca5bf4a50",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa632edb-a784-4271-89df-49a4fbb4fd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (3900,)\n",
      "y_train shape: (3900,)\n",
      "X_test shape: (1672,)\n",
      "y_test shape: (1672,)\n"
     ]
    }
   ],
   "source": [
    "X = spam['message']\n",
    "y = spam['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 0.3 = 30%\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166c1f48-238d-484f-a8fd-192ae82bce54",
   "metadata": {},
   "source": [
    "#### Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f73918-a91a-43f9-8297-e2a542ad4a0b",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.LabelEncoder.html#sklearn.preprocessing.LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e9011b9-f6fe-47b5-a3fc-49c72b5a6493",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb30ffc8-1f18-4568-a03d-16572dabdd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer: 8672 Features\n",
      "X_train_vectorized (3900, 8672) and X_valid_vectorized (1672, 8672)\n",
      "y_train_num: [1 0 0 0 0]\n",
      "y_valid_num: [0 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X)\n",
    "print(f\"CountVectorizer: {len(vectorizer.vocabulary_)} Features\")\n",
    "\n",
    "X_train_vectorized = vectorizer.transform(X_train)\n",
    "X_valid_vectorized = vectorizer.transform(X_valid)\n",
    "\n",
    "print(f\"X_train_vectorized {X_train_vectorized.shape} and X_valid_vectorized {X_valid_vectorized.shape}\")\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_num = label_encoder.fit_transform(y_train)\n",
    "y_valid_num = label_encoder.transform(y_valid)\n",
    "\n",
    "print(\"y_train_num:\", y_train_num[:5])\n",
    "print(\"y_valid_num:\", y_valid_num[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bcfbb7-d943-4bf1-be4b-4299807c847a",
   "metadata": {},
   "source": [
    "#### Step 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043098b5-e79c-4eab-8d29-2fb0f554fe12",
   "metadata": {},
   "source": [
    "Training des Naive Bayes Classifiers: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e49b062-f233-45d7-89d1-39186c536a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebd1cc5c-f053-47f8-9ad0-a2abf83bd9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9796650717703349"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = naive_bayes.MultinomialNB(alpha=0.2) \n",
    "clf.fit(X_train_vectorized, y_train_num) \n",
    "predictions = clf.predict(X_valid_vectorized) \n",
    "metrics.accuracy_score(predictions, y_valid_num) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eae1a1f-ca8c-432d-ba64-120f57830609",
   "metadata": {},
   "source": [
    "#### Step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b9e327c-ebb8-410a-9289-fd380a5d9ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg=vectorizer.transform([\"Congratulations! You've won a complimentary entry to the exclusive VIP event. Claim your free pass for the grand finale on June 15, 2023, by texting VIP to 44882. Standard text messaging rates apply. For more details, call 1-800-123-4567. Don't miss out on this incredible opportunity! Terms and conditions apply. Must be 18 or older to participate.\"]) \n",
    "clf.predict(msg) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
