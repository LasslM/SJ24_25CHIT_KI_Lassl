{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92eea108-3ee3-4c0b-a0f7-1e1c4d899ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "One-Hot-Kodierung mit pandas get_dummies: \n",
      "    kategorie_Bücher  kategorie_Elektronik  kategorie_Kleidung\n",
      "0                  0                     1                   0\n",
      "1                  0                     0                   1\n",
      "2                  1                     0                   0\n",
      "3                  0                     1                   0\n",
      "4                  0                     1                   0\n",
      "5                  1                     0                   0\n",
      "6                  0                     0                   1\n",
      "7                  1                     0                   0\n",
      "8                  0                     1                   0\n",
      "9                  0                     0                   1\n",
      "10                 1                     0                   0\n",
      "11                 0                     1                   0\n",
      "12                 1                     0                   0\n",
      "13                 0                     1                   0\n",
      "14                 0                     0                   1\n",
      "15                 0                     0                   1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('products.csv', encoding='UTF-8')\n",
    "df_dummies = pd.get_dummies(df, columns=['kategorie']).astype(int)\n",
    "\n",
    "#ergebnis anzeigen\n",
    "print('\\nOne-Hot-Kodierung mit pandas get_dummies: ')\n",
    "print(df_dummies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc471d06-7bc8-42eb-8ebe-a4d578ce7ad2",
   "metadata": {},
   "source": [
    "## Converting Text to Featrures II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8663a544-1bd2-4135-86ce-29720d45cbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.9/site-packages (from scikit-learn) (2.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.9/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.9/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.9/site-packages (from scikit-learn) (1.4.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb964378-276f-4935-a3b6-db215bf623d7",
   "metadata": {},
   "source": [
    "#### 4.2.1 Textklassifizierung am Beispiel Spam/Ham "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91099dce-49e3-433e-9d87-f7a916643952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8598838e-393c-480b-8244-7ef487368700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vokabular {'nlp': 8, 'unlocks': 12, 'insights': 5, 'evolving': 3, 'ml': 7, 'learns': 6, 'patterns': 9, 'applications': 1, 'abound': 0, 'preprocessing': 10, 'crucial': 2, 'for': 4, 'understanding': 11}\n",
      "Vokabular {'nlp': 8, 'unlocks': 12, 'insights': 5, 'evolving': 3, 'ml': 7, 'learns': 6, 'patterns': 9, 'applications': 1, 'abound': 0, 'preprocessing': 10, 'crucial': 2, 'for': 4, 'understanding': 11}\n",
      "Bag of Words\n",
      " [[0 0 0 1 0 1 0 0 2 0 0 0 1]\n",
      " [1 1 0 0 0 0 1 2 0 1 0 0 0]\n",
      " [0 0 1 0 1 0 0 0 2 0 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "text = [     \n",
    "    \"NLP unlocks insights, NLP evolving.\",     \n",
    "    \"ML learns patterns; ML applications abound.\",     \n",
    "    \"NLP preprocessing crucial for NLP understanding.\" \n",
    "] \n",
    "\n",
    "vectorizer = CountVectorizer() \n",
    "\n",
    "# Erstellt das Vokabular aus den Textdaten \n",
    "X=vectorizer.fit(text) \n",
    "\n",
    "print(\"Vokabular\", vectorizer.vocabulary_)\n",
    "\n",
    "# Features ausgeben \n",
    "print(\"Vokabular\", vectorizer.vocabulary_) \n",
    "\n",
    "# Text basierend auf Vokabular vektorisieren. Ergebnis ist BoW \n",
    "X=vectorizer.transform(text) \n",
    "\n",
    "print(\"Bag of Words\\n\", X.toarray()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73e8221a-4113-4299-9b76-4b154dc0f865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target                                            message\n",
       "0       ham  Go until jurong point, crazy.. Available only ...\n",
       "1       ham                      Ok lar... Joking wif u oni...\n",
       "2      spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       ham  U dun say so early hor... U c already then say...\n",
       "4       ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...     ...                                                ...\n",
       "5567   spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568    ham              Will Ì_ b going to esplanade fr home?\n",
       "5569    ham  Pity, * was in mood for that. So...any other s...\n",
       "5570    ham  The guy did some bitching but I acted like i'd...\n",
       "5571    ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam = pd.read_csv(\"spam.csv\", encoding='latin1')\n",
    "spam = spam[[\"v1\",\"v2\"]]\n",
    "spam.columns = ['target', 'message']\n",
    "spam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4398ba69-4186-4dd9-867c-4f2b79fafc3b",
   "metadata": {},
   "source": [
    "#### Step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6881491f-6b3e-4a0d-ab59-3abca5bf4a50",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa632edb-a784-4271-89df-49a4fbb4fd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (3900,)\n",
      "y_train shape: (3900,)\n",
      "X_test shape: (1672,)\n",
      "y_test shape: (1672,)\n"
     ]
    }
   ],
   "source": [
    "X = spam['message']\n",
    "y = spam['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 0.3 = 30%\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166c1f48-238d-484f-a8fd-192ae82bce54",
   "metadata": {},
   "source": [
    "#### Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f73918-a91a-43f9-8297-e2a542ad4a0b",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.LabelEncoder.html#sklearn.preprocessing.LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e9011b9-f6fe-47b5-a3fc-49c72b5a6493",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb30ffc8-1f18-4568-a03d-16572dabdd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer: 8672 Features\n",
      "X_train_vectorized (3900, 8672) and X_valid_vectorized (1672, 8672)\n",
      "y_train_num: [1 0 0 0 0]\n",
      "y_valid_num: [0 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X)\n",
    "print(f\"CountVectorizer: {len(vectorizer.vocabulary_)} Features\")\n",
    "\n",
    "X_train_vectorized = vectorizer.transform(X_train)\n",
    "X_valid_vectorized = vectorizer.transform(X_valid)\n",
    "\n",
    "print(f\"X_train_vectorized {X_train_vectorized.shape} and X_valid_vectorized {X_valid_vectorized.shape}\")\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_num = label_encoder.fit_transform(y_train)\n",
    "y_valid_num = label_encoder.transform(y_valid)\n",
    "\n",
    "print(\"y_train_num:\", y_train_num[:5])\n",
    "print(\"y_valid_num:\", y_valid_num[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a07ca909-5633-4daa-abd3-61302a91b469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'flying',\n",
       " 'pokkiri',\n",
       " 'urgh',\n",
       " 'meaningless',\n",
       " 'callers',\n",
       " '3xx',\n",
       " 'stopsms',\n",
       " 'santacalling',\n",
       " 'html',\n",
       " 'meg',\n",
       " 'inpersonation',\n",
       " 'seing',\n",
       " 'friendship',\n",
       " 'point',\n",
       " 'rgent',\n",
       " 'hair',\n",
       " 'moon',\n",
       " 'moved',\n",
       " 'eppolum',\n",
       " 'airtel',\n",
       " 'tree',\n",
       " 'spotty',\n",
       " 'kano',\n",
       " 'sirji',\n",
       " 'possession',\n",
       " 'wicket',\n",
       " 'moving',\n",
       " 'ringtoneking',\n",
       " 'bills',\n",
       " 'eh',\n",
       " '9ja',\n",
       " 'rply',\n",
       " 'satanic',\n",
       " '800',\n",
       " 'travelling',\n",
       " 'spjanuary',\n",
       " 'chechi',\n",
       " 'hiding',\n",
       " 'trains',\n",
       " 'shijas',\n",
       " 'wah',\n",
       " 'secretary',\n",
       " 'asap',\n",
       " 'anonymous',\n",
       " '150pm',\n",
       " 'clearer',\n",
       " 'l8r',\n",
       " '09058094594',\n",
       " 'residency',\n",
       " 'vu',\n",
       " 'nig',\n",
       " 'referin',\n",
       " 'smell',\n",
       " '04',\n",
       " 'waste',\n",
       " 'agent',\n",
       " 'sk38xh',\n",
       " 'been',\n",
       " 'sept',\n",
       " 'passes',\n",
       " 'ishtamayoo',\n",
       " 'kingdom',\n",
       " 'must',\n",
       " 'woke',\n",
       " 'walkin',\n",
       " 'thinkin',\n",
       " 'mumtaz',\n",
       " 'destination',\n",
       " 'bognor',\n",
       " 'gpu',\n",
       " '27',\n",
       " 'armand',\n",
       " 'cn',\n",
       " '0906346330',\n",
       " 'cres',\n",
       " 'throw',\n",
       " 'recd',\n",
       " 'categories',\n",
       " 'help08700621170150p',\n",
       " 'crucial',\n",
       " 'dollar',\n",
       " 'sayy',\n",
       " 'tellmiss',\n",
       " 'hearted',\n",
       " 'helen',\n",
       " 'young',\n",
       " 'disk',\n",
       " 'shangela',\n",
       " 'themob',\n",
       " 'heap',\n",
       " 'ì¼1',\n",
       " 'looks',\n",
       " 'sooo',\n",
       " 'ceri',\n",
       " 'dusk',\n",
       " 'evone',\n",
       " 'autocorrect',\n",
       " 'anthony',\n",
       " 'downstem',\n",
       " 'bx',\n",
       " 'bloomberg',\n",
       " '09111032124',\n",
       " 'cereals',\n",
       " 'jjc',\n",
       " 'com1win150ppmx3age16',\n",
       " 'zealand',\n",
       " 'oni',\n",
       " 'recpt',\n",
       " '1pm',\n",
       " '118p',\n",
       " 'aeroplane',\n",
       " 'crckt',\n",
       " 'wld',\n",
       " 'hardest',\n",
       " 'wat',\n",
       " 'burger',\n",
       " '09095350301',\n",
       " 'chop',\n",
       " 'flim',\n",
       " 'rajnikant',\n",
       " 'cooperative',\n",
       " '88066',\n",
       " 'project',\n",
       " 'never',\n",
       " '83370',\n",
       " 'gal',\n",
       " 'rings',\n",
       " 'iåõllspeak',\n",
       " 'riley',\n",
       " 'algebra',\n",
       " 'dogg',\n",
       " 'serving',\n",
       " 'baaaaaaaabe',\n",
       " 'admit',\n",
       " 'essential',\n",
       " 'festival',\n",
       " '81618',\n",
       " 'released',\n",
       " 'yi',\n",
       " 'den',\n",
       " 'weds',\n",
       " 'conference',\n",
       " 'spoons',\n",
       " 'ystrday',\n",
       " 'affection',\n",
       " 'sextextuk',\n",
       " 'aeronautics',\n",
       " 'spider',\n",
       " 'retrieve',\n",
       " 'unlike',\n",
       " 'bell',\n",
       " 'busty',\n",
       " 'frog',\n",
       " 'reception',\n",
       " 'harri',\n",
       " '910',\n",
       " 'setting',\n",
       " 'situation',\n",
       " 'chatlines',\n",
       " 'jazz',\n",
       " 'jst',\n",
       " 'imf',\n",
       " 'suman',\n",
       " 'paru',\n",
       " 'reminds',\n",
       " 'blastin',\n",
       " 'bugis',\n",
       " 'mids',\n",
       " 'witin',\n",
       " 'ridden',\n",
       " 'prescripiton',\n",
       " 'hip',\n",
       " 'secrets',\n",
       " 'rooms',\n",
       " 'peach',\n",
       " 'cysts',\n",
       " 'cabin',\n",
       " 'dare',\n",
       " 'clue',\n",
       " 'stores',\n",
       " 'tnc',\n",
       " 'lyk',\n",
       " 'ger',\n",
       " 'mmmm',\n",
       " 'hope',\n",
       " 'submitting',\n",
       " 'accordingly',\n",
       " 'off',\n",
       " 'nokia',\n",
       " '220cm2',\n",
       " 'creative',\n",
       " '7250',\n",
       " 'anyplaces',\n",
       " 'westonzoyland',\n",
       " 'brison',\n",
       " 'diff',\n",
       " 'improved',\n",
       " 'haul',\n",
       " 'athome',\n",
       " '09066358361',\n",
       " 'matthew',\n",
       " 'bucks',\n",
       " 'south',\n",
       " 'xy',\n",
       " 'genius',\n",
       " 'k61',\n",
       " 'awww',\n",
       " 'elephant',\n",
       " 'quizclub',\n",
       " 'haiz',\n",
       " 'devouring',\n",
       " 'mei',\n",
       " '150p',\n",
       " 'related',\n",
       " 'jelly',\n",
       " 'westshore',\n",
       " 'psp',\n",
       " 'phone750',\n",
       " 'brin',\n",
       " 'recognise',\n",
       " 'couldnåõt',\n",
       " '50pmmorefrommobile2bremoved',\n",
       " 'illness',\n",
       " 'power',\n",
       " '08712300220',\n",
       " 'shadow',\n",
       " '84484',\n",
       " 'tai',\n",
       " 'wesley',\n",
       " 'alert',\n",
       " 'violence',\n",
       " 'gauti',\n",
       " 'copy',\n",
       " 'truly',\n",
       " 'isn',\n",
       " 'crisis',\n",
       " 'horny',\n",
       " 'fires',\n",
       " 'cant',\n",
       " 'evaluation',\n",
       " 'vary',\n",
       " 'warming',\n",
       " 'pobox36504w45wq',\n",
       " 'dis',\n",
       " 'unconvinced',\n",
       " 'suzy',\n",
       " 'funeral',\n",
       " '68866',\n",
       " 'winning',\n",
       " 'praying',\n",
       " 'basically',\n",
       " 'kochi',\n",
       " 'whole',\n",
       " 'cos',\n",
       " 'goss',\n",
       " 'activ8',\n",
       " 'nooooooo',\n",
       " '07808',\n",
       " 'sth',\n",
       " 'conversations',\n",
       " 'bros',\n",
       " 'needle',\n",
       " 'clever',\n",
       " 'walsall',\n",
       " 'slap',\n",
       " 'admirer',\n",
       " 'ig11',\n",
       " 'anniversary',\n",
       " 'guild',\n",
       " 'customers',\n",
       " 'infront',\n",
       " 'dec',\n",
       " 'wrk',\n",
       " '3030',\n",
       " '11pm',\n",
       " '08701752560',\n",
       " 'smacks',\n",
       " 'ahold',\n",
       " 'dieting',\n",
       " 'maaaan',\n",
       " 'ilol',\n",
       " '09058094454',\n",
       " 'ennal',\n",
       " 'thandiyachu',\n",
       " 'travel',\n",
       " 'attempt',\n",
       " 'without',\n",
       " 'costa',\n",
       " 'borin',\n",
       " 'ugadi',\n",
       " 'duvet',\n",
       " 'mobileupd8',\n",
       " 'preponed',\n",
       " 'weighed',\n",
       " 'dramastorm',\n",
       " 'reached',\n",
       " 'ummifying',\n",
       " 'belongs',\n",
       " 'nit',\n",
       " 'stopbcm',\n",
       " 'adewale',\n",
       " 'constantly',\n",
       " 'display',\n",
       " 'flaked',\n",
       " 'weirdy',\n",
       " 'sensitive',\n",
       " 'removal',\n",
       " 'immed',\n",
       " 'monoc',\n",
       " 'sweet',\n",
       " 'prof',\n",
       " 'tears',\n",
       " 'worries',\n",
       " 'worry',\n",
       " 'does',\n",
       " '1win150ppmx3',\n",
       " 'ummmmmaah',\n",
       " 'looked',\n",
       " 'arise',\n",
       " 'fishrman',\n",
       " 'photos',\n",
       " 'na',\n",
       " 'presleys',\n",
       " '08714342399',\n",
       " 'years',\n",
       " 'unbelievable',\n",
       " '125gift',\n",
       " 'environment',\n",
       " 'uhhhhrmm',\n",
       " 'chinatown',\n",
       " 'hack',\n",
       " 'dumb',\n",
       " 'enufcredeit',\n",
       " 'lifebook',\n",
       " 'rt',\n",
       " 'paying',\n",
       " 'so',\n",
       " 'increase',\n",
       " 'dancin',\n",
       " 'pierre',\n",
       " 'princes',\n",
       " 'chrgd',\n",
       " 'prix',\n",
       " 'alfie',\n",
       " 'arent',\n",
       " 'kuch',\n",
       " 'icky',\n",
       " 'leaf',\n",
       " 'common',\n",
       " 'personality',\n",
       " 'pure',\n",
       " '08701417012150p',\n",
       " 'traveling',\n",
       " 'scoring',\n",
       " 'byatch',\n",
       " 'across',\n",
       " 'clocks',\n",
       " 'jd',\n",
       " '09058097218',\n",
       " 'helens',\n",
       " 'iron',\n",
       " 'ondu',\n",
       " '820554ad0a1705572711',\n",
       " '2yrs',\n",
       " '9307622',\n",
       " 'folks',\n",
       " 'entertaining',\n",
       " 'bullshit',\n",
       " 'sack',\n",
       " 'arcade',\n",
       " 'shining',\n",
       " '6months',\n",
       " 'online',\n",
       " '08712402902',\n",
       " '0quit',\n",
       " '0871212025016',\n",
       " 'beta',\n",
       " 'changes',\n",
       " 'payment',\n",
       " 'voted',\n",
       " 'sweetheart',\n",
       " 'printed',\n",
       " 'pobox365o4w45wq',\n",
       " 'sarasota',\n",
       " 'mistakes',\n",
       " 'driving',\n",
       " 'noise',\n",
       " 'crap',\n",
       " 'manage',\n",
       " 'polo',\n",
       " 'wats',\n",
       " 'florida',\n",
       " 'tomorrow',\n",
       " 'baaaaabe',\n",
       " 'loveme',\n",
       " 'becoz',\n",
       " 'named',\n",
       " 'rg21',\n",
       " 'rwm',\n",
       " 'prescribed',\n",
       " '29',\n",
       " 'scotland',\n",
       " 'waking',\n",
       " 'cover',\n",
       " 'most',\n",
       " 'oja',\n",
       " 'biggest',\n",
       " 'ah',\n",
       " 'perumbavoor',\n",
       " 'available',\n",
       " 'propsd',\n",
       " 'ideal',\n",
       " 'iff',\n",
       " 'profile',\n",
       " 'cat',\n",
       " 'bitching',\n",
       " 'guy',\n",
       " 'prabu',\n",
       " 'der',\n",
       " 'virtual',\n",
       " '8552',\n",
       " '0870241182716',\n",
       " 'kilos',\n",
       " 'salmon',\n",
       " 'lessons',\n",
       " 'cal',\n",
       " 'nag',\n",
       " 'realising',\n",
       " 'wedding',\n",
       " 'rowdy',\n",
       " 'gonna',\n",
       " 'askd',\n",
       " '150ppm',\n",
       " '09065069120',\n",
       " 'units',\n",
       " '9ae',\n",
       " '872',\n",
       " 'groovy',\n",
       " 'rofl',\n",
       " 'garbage',\n",
       " 'newest',\n",
       " '20',\n",
       " '08448714184',\n",
       " 'edition',\n",
       " 'british',\n",
       " '02',\n",
       " 'ringing',\n",
       " '83355',\n",
       " 'pleasure',\n",
       " 'onum',\n",
       " 'family',\n",
       " 'bed',\n",
       " 'hairdressers',\n",
       " 'pushes',\n",
       " 'lul',\n",
       " 'my',\n",
       " 'hl',\n",
       " 'dane',\n",
       " '09099726481',\n",
       " 'seems',\n",
       " 'terror',\n",
       " 'avin',\n",
       " 'w111wx',\n",
       " 'unfortunately',\n",
       " 'aiyah',\n",
       " 'schools',\n",
       " 'vpod',\n",
       " 'claypot',\n",
       " 'dungerees',\n",
       " 'macs',\n",
       " 'fiend',\n",
       " 'tackle',\n",
       " 'gone',\n",
       " '30th',\n",
       " 'prizeswith',\n",
       " 'beatings',\n",
       " 'vasai',\n",
       " 'favorite',\n",
       " 'alternative',\n",
       " 'justbeen',\n",
       " 'gravity',\n",
       " 'ld',\n",
       " 'bring',\n",
       " 'swell',\n",
       " 'hoo',\n",
       " 'akon',\n",
       " 'did',\n",
       " 'reading',\n",
       " 'bout',\n",
       " 'appointments',\n",
       " 'women',\n",
       " 'kidz',\n",
       " 'helps',\n",
       " 'reasons',\n",
       " 'goes',\n",
       " 'fancy',\n",
       " 'free2day',\n",
       " 'funk',\n",
       " 'upping',\n",
       " 'lined',\n",
       " 'wap',\n",
       " 'near',\n",
       " 'kfc',\n",
       " 'footprints',\n",
       " 'events',\n",
       " 'm227xy',\n",
       " 'loud',\n",
       " 'digi',\n",
       " 'hunt',\n",
       " 'between',\n",
       " 'land',\n",
       " '09064017305',\n",
       " 'claimcode',\n",
       " 'protect',\n",
       " 'maximum',\n",
       " 'side',\n",
       " 'signal',\n",
       " 'skins',\n",
       " 'yupz',\n",
       " 'arul',\n",
       " '1stchoice',\n",
       " 'grocers',\n",
       " 'videosounds',\n",
       " 'missunderstding',\n",
       " 'bookshelf',\n",
       " 'rajas',\n",
       " 'restrictions',\n",
       " 'norcorp',\n",
       " 'myself',\n",
       " 'slip',\n",
       " 'pract',\n",
       " '09071512432',\n",
       " 'birth',\n",
       " 'command',\n",
       " 'weekends',\n",
       " 'irritation',\n",
       " '69698',\n",
       " 'rummer',\n",
       " '09064019788',\n",
       " '4info',\n",
       " 'pobox12n146tf150p',\n",
       " 'olowoyey',\n",
       " 'thkin',\n",
       " 'census',\n",
       " 'necesity',\n",
       " '69669',\n",
       " 'dl',\n",
       " 'nannys',\n",
       " 'sink',\n",
       " 'jason',\n",
       " 'tea',\n",
       " 'chk',\n",
       " 'fifty',\n",
       " '50p',\n",
       " 'jungle',\n",
       " 'humanities',\n",
       " '0430',\n",
       " '10k',\n",
       " 'temple',\n",
       " 'vehicle',\n",
       " 'belong',\n",
       " 'by',\n",
       " 'canal',\n",
       " 'pookie',\n",
       " 'aspects',\n",
       " 'plural',\n",
       " 'accumulation',\n",
       " 'unable',\n",
       " 'awake',\n",
       " 'spoiled',\n",
       " 'ramaduth',\n",
       " 'jolt',\n",
       " 'insurance',\n",
       " 'raksha',\n",
       " 'depression',\n",
       " 'expecting',\n",
       " 'decent',\n",
       " 'belligerent',\n",
       " 'throws',\n",
       " 'key',\n",
       " 'ts',\n",
       " 'wonder',\n",
       " '40',\n",
       " 'heard',\n",
       " 'misfits',\n",
       " 'which',\n",
       " 'heart',\n",
       " 'billed',\n",
       " 'horo',\n",
       " 'ofice',\n",
       " 'disaster',\n",
       " 'syllabus',\n",
       " 'frm',\n",
       " 'ofå',\n",
       " 'fear',\n",
       " 'carolina',\n",
       " 'mother',\n",
       " 'barred',\n",
       " 'port',\n",
       " 'burial',\n",
       " 'yelow',\n",
       " '08719180219',\n",
       " 'dial',\n",
       " 'nan',\n",
       " 'cheap',\n",
       " 'calicut',\n",
       " 'ranjith',\n",
       " '08718727868',\n",
       " 'can',\n",
       " 'vegetables',\n",
       " 'gin',\n",
       " '09061790121',\n",
       " 'hui',\n",
       " '150p16',\n",
       " 'stairs',\n",
       " 'naal',\n",
       " 'dialogue',\n",
       " '150ppermesssubscription',\n",
       " 'sickness',\n",
       " 'lunsford',\n",
       " 'diapers',\n",
       " 'guidance',\n",
       " 'table',\n",
       " '400thousad',\n",
       " 'kz',\n",
       " 'religiously',\n",
       " 'motor',\n",
       " 'platt',\n",
       " 'topped',\n",
       " 'abta',\n",
       " 'mobile',\n",
       " 'shortage',\n",
       " 'cost',\n",
       " 'cumming',\n",
       " 'girlfrnd',\n",
       " 'watchng',\n",
       " 'sort',\n",
       " 'arguing',\n",
       " 'hont',\n",
       " 'wan',\n",
       " '300p',\n",
       " 'parchi',\n",
       " 'db',\n",
       " 'sankranti',\n",
       " 'cer',\n",
       " 'felt',\n",
       " 'film',\n",
       " 'november',\n",
       " 'nurses',\n",
       " 'joker',\n",
       " 'tactful',\n",
       " 'afraid',\n",
       " 'netun',\n",
       " 'sum',\n",
       " 'datebox1282essexcm61xn',\n",
       " 'knock',\n",
       " 'relatives',\n",
       " 'gage',\n",
       " 'number',\n",
       " 'bcz',\n",
       " 'season',\n",
       " 'helping',\n",
       " '26th',\n",
       " 'up',\n",
       " 'cheaper',\n",
       " 'perfume',\n",
       " 'invite',\n",
       " 'useless',\n",
       " 'counts',\n",
       " 'entertain',\n",
       " 'wuld',\n",
       " 'mths',\n",
       " 'spook',\n",
       " 'flies',\n",
       " 'drive',\n",
       " 'baig',\n",
       " 'pump',\n",
       " 'unsub',\n",
       " 'degrees',\n",
       " 'yay',\n",
       " 'right',\n",
       " 'ak',\n",
       " 'bruv',\n",
       " 'boys',\n",
       " 'gary',\n",
       " 'everyboy',\n",
       " 'camera',\n",
       " 'uawake',\n",
       " 'touch',\n",
       " 'city',\n",
       " 'gimme',\n",
       " '08006344447',\n",
       " 'ours',\n",
       " '1lemon',\n",
       " 'notified',\n",
       " '2814032',\n",
       " 'rodger',\n",
       " 'tomorro',\n",
       " 'smiled',\n",
       " 'spark',\n",
       " 'done',\n",
       " 'helloooo',\n",
       " 'onwards',\n",
       " '32323',\n",
       " 'hotels',\n",
       " 'boye',\n",
       " 'lo',\n",
       " 'personal',\n",
       " 'box403',\n",
       " 'buff',\n",
       " 'ke',\n",
       " 'laden',\n",
       " 'truck',\n",
       " 'mail',\n",
       " 'selling',\n",
       " 'parked',\n",
       " 'keluviri',\n",
       " 'tom',\n",
       " 'wishes',\n",
       " 'di',\n",
       " 'brdget',\n",
       " 'nosh',\n",
       " 'you',\n",
       " 'doesnt',\n",
       " 'fr',\n",
       " 'apples',\n",
       " 'battle',\n",
       " 'go2sri',\n",
       " 'fyi',\n",
       " 'saves',\n",
       " 'racal',\n",
       " 'hun',\n",
       " 'spontaneously',\n",
       " 'tscs08714740323',\n",
       " 'research',\n",
       " 'chg',\n",
       " 'complaining',\n",
       " 'movietrivia',\n",
       " 'snot',\n",
       " 'behind',\n",
       " 'necklace',\n",
       " 'poortiyagi',\n",
       " 'sometime',\n",
       " 'sos',\n",
       " 'thatåõs',\n",
       " 'thank',\n",
       " '24m',\n",
       " 'isnt',\n",
       " 'prior',\n",
       " 'tall',\n",
       " 'aid',\n",
       " 'wasn',\n",
       " '6ph',\n",
       " 'careless',\n",
       " 'omg',\n",
       " 'hari',\n",
       " 'in2',\n",
       " 'zindgi',\n",
       " 'maid',\n",
       " 'india',\n",
       " '0845',\n",
       " '5k',\n",
       " 'maintaining',\n",
       " 'brilliant',\n",
       " 'eating',\n",
       " 'aphexåõs',\n",
       " 'janx',\n",
       " 'otherwise',\n",
       " 'receiving',\n",
       " 'respectful',\n",
       " 'beerage',\n",
       " 'inclusive',\n",
       " 'dance',\n",
       " 'stereo',\n",
       " '89034',\n",
       " 'soul',\n",
       " 'played',\n",
       " 'madstini',\n",
       " 'paths',\n",
       " 'shipped',\n",
       " 'rain',\n",
       " 'billing',\n",
       " 'may',\n",
       " 'thanx4',\n",
       " '09050005321',\n",
       " 'explosive',\n",
       " 'åòit',\n",
       " 'planning',\n",
       " '078',\n",
       " 'hilarious',\n",
       " 'height',\n",
       " 'cya',\n",
       " 'load',\n",
       " 'restrict',\n",
       " 'has',\n",
       " 'lt',\n",
       " 'ready',\n",
       " '12',\n",
       " 'bck',\n",
       " 'giv',\n",
       " 'blanket',\n",
       " '87077',\n",
       " 'only1more',\n",
       " 'public',\n",
       " 'sometme',\n",
       " 'sehwag',\n",
       " 'male',\n",
       " 'vill',\n",
       " 'pobox75ldns7',\n",
       " 'jot',\n",
       " 'christ',\n",
       " 'venugopal',\n",
       " 'banter',\n",
       " 'pizza',\n",
       " 'deep',\n",
       " 'rock',\n",
       " 'coat',\n",
       " '4w',\n",
       " 'atural',\n",
       " 'xxx',\n",
       " '8p',\n",
       " 'business',\n",
       " 'harry',\n",
       " 'hon',\n",
       " 'lttrs',\n",
       " '10',\n",
       " 'box39822',\n",
       " 'mustprovide',\n",
       " 'ó_',\n",
       " 'disappointment',\n",
       " 'alot',\n",
       " 'little',\n",
       " 'intrepid',\n",
       " 'deus',\n",
       " 'poker',\n",
       " 'fringe',\n",
       " 'taunton',\n",
       " '66',\n",
       " 'appreciated',\n",
       " '0578',\n",
       " 'adoring',\n",
       " 'sherawat',\n",
       " 'fancied',\n",
       " 'champ',\n",
       " 'films',\n",
       " '89105',\n",
       " 'kickoff',\n",
       " 'tessy',\n",
       " 'fatty',\n",
       " 'cl',\n",
       " '07046744435',\n",
       " 'grief',\n",
       " 'gon',\n",
       " 'network',\n",
       " 'spl',\n",
       " 'kalstiya',\n",
       " 'vouch4me',\n",
       " 'heater',\n",
       " 'woulda',\n",
       " 'dengra',\n",
       " '81303',\n",
       " 'shindig',\n",
       " 'jane',\n",
       " 'likeyour',\n",
       " 'salesman',\n",
       " 'him',\n",
       " 'itna',\n",
       " 'kg',\n",
       " 'opening',\n",
       " 'cruisin',\n",
       " '89693',\n",
       " 'ms',\n",
       " 'court',\n",
       " 'shrub',\n",
       " 'pull',\n",
       " 'vday',\n",
       " 'story',\n",
       " '08715705022',\n",
       " 'enter',\n",
       " 'chosen',\n",
       " 'pushbutton',\n",
       " 'bold',\n",
       " 'hanuman',\n",
       " 'belt',\n",
       " '87021',\n",
       " 'pos',\n",
       " '81151',\n",
       " 'front',\n",
       " 'cast',\n",
       " 'heehee',\n",
       " 'replacing',\n",
       " 'howard',\n",
       " 'jorge',\n",
       " 'voicemail',\n",
       " '09058091854',\n",
       " 'maangalyam',\n",
       " 'strips',\n",
       " 'hrs',\n",
       " 'vomiting',\n",
       " 'samachara',\n",
       " 'pobox84',\n",
       " 'finding',\n",
       " 'cried',\n",
       " 'reality',\n",
       " 'disc',\n",
       " 'lol',\n",
       " '83738',\n",
       " 'lesson',\n",
       " 'ava',\n",
       " 'educational',\n",
       " 'loko',\n",
       " 'proverb',\n",
       " 'snoring',\n",
       " 'use',\n",
       " 'isaiah',\n",
       " 'upcharge',\n",
       " 'hes',\n",
       " 'liao',\n",
       " 'idu',\n",
       " 'clubmoby',\n",
       " 'answerin',\n",
       " 'farting',\n",
       " 'playng',\n",
       " 'messaged',\n",
       " 'eachother',\n",
       " '09',\n",
       " 'ghodbandar',\n",
       " '2wu',\n",
       " 'nigpun',\n",
       " 'pansy',\n",
       " 'bishan',\n",
       " 'or',\n",
       " 'inlude',\n",
       " 'brolly',\n",
       " 'come',\n",
       " 'wenwecan',\n",
       " 'packing',\n",
       " '08714712412',\n",
       " 'advance',\n",
       " 'whatsup',\n",
       " 'innocent',\n",
       " 'beautiful',\n",
       " 'mt',\n",
       " 'tmrw',\n",
       " '4fil',\n",
       " 'adding',\n",
       " 'program',\n",
       " 'askin',\n",
       " 'evaporated',\n",
       " 'theacusations',\n",
       " 'name1',\n",
       " 'buzzzz',\n",
       " 'delete',\n",
       " '09061743810',\n",
       " 'operate',\n",
       " 'mahaveer',\n",
       " 'asks',\n",
       " 'tiwary',\n",
       " 'totes',\n",
       " 'oreos',\n",
       " 'apologize',\n",
       " 'cudnt',\n",
       " 'types',\n",
       " 'scenario',\n",
       " 'aquarius',\n",
       " 'sts',\n",
       " 'overdid',\n",
       " 'ûï',\n",
       " 'w1a',\n",
       " 'causing',\n",
       " 'twenty',\n",
       " 'forth',\n",
       " 'oli',\n",
       " 'aunts',\n",
       " 'izzit',\n",
       " 'das',\n",
       " 'morefrmmob',\n",
       " 'flow',\n",
       " 'jan',\n",
       " 'minnaminunginte',\n",
       " 'windows',\n",
       " 'stadium',\n",
       " '09065174042',\n",
       " 'marrge',\n",
       " 'wake',\n",
       " 'moral',\n",
       " 'handing',\n",
       " 'benefits',\n",
       " 'chase',\n",
       " 'mesages',\n",
       " 'mum',\n",
       " 'voda',\n",
       " 'boltblue',\n",
       " 'living',\n",
       " 'six',\n",
       " 'await',\n",
       " 'surrender',\n",
       " 'relationship',\n",
       " 'eire',\n",
       " 'late',\n",
       " ...}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bcfbb7-d943-4bf1-be4b-4299807c847a",
   "metadata": {},
   "source": [
    "#### Step 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043098b5-e79c-4eab-8d29-2fb0f554fe12",
   "metadata": {},
   "source": [
    "Training des Naive Bayes Classifiers: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e49b062-f233-45d7-89d1-39186c536a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebd1cc5c-f053-47f8-9ad0-a2abf83bd9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9796650717703349"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = naive_bayes.MultinomialNB(alpha=0.2) \n",
    "clf.fit(X_train_vectorized, y_train_num) \n",
    "predictions = clf.predict(X_valid_vectorized) \n",
    "metrics.accuracy_score(predictions, y_valid_num) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eae1a1f-ca8c-432d-ba64-120f57830609",
   "metadata": {},
   "source": [
    "#### Step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b9e327c-ebb8-410a-9289-fd380a5d9ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg=vectorizer.transform([\"Congratulations! You've won a complimentary entry to the exclusive VIP event. Claim your free pass for the grand finale on June 15, 2023, by texting VIP to 44882. Standard text messaging rates apply. For more details, call 1-800-123-4567. Don't miss out on this incredible opportunity! Terms and conditions apply. Must be 18 or older to participate.\"]) \n",
    "clf.predict(msg) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e5a6fb-e618-415f-97ba-a99f22859d9a",
   "metadata": {},
   "source": [
    "## Converting Text to Featrures III"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb622085-8a92-4321-bb95-c56725dba382",
   "metadata": {},
   "source": [
    "#### Term Frequency-Inverse Document Frequency (TF-IDF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8272aea0-86bf-4013-9470-cd16a358e158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abound' 'applications' 'crucial' 'evolving' 'for' 'insights' 'learns'\n",
      " 'ml' 'nlp' 'patterns' 'preprocessing' 'understanding' 'unlocks']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "text=[\n",
    "    \"NLP unlocks insights, NLP evolving.\",     \n",
    "    \"ML learns patterns; ML applications abound.\",     \n",
    "    \"NLP preprocessing crucial for NLP understanding.\" \n",
    "] \n",
    "\n",
    "vectorizer = TfidfVectorizer() \n",
    "X = vectorizer.fit_transform(text) \n",
    "print(vectorizer.get_feature_names_out()) # TF-IDF-Vektordaten ausgeben print(X.toarray() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f1b573f-c877-4a00-94e2-73b1e6dd9cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.9627    -0.91824   -2.0265     0.96333   -1.5311     0.33585\n",
      "  1.4037    -2.0414    -2.7074     2.2531     1.2997    -0.0079919\n",
      "  0.1093    -2.0392     1.8114     2.9421    -2.9791    -1.1868\n",
      " -5.0019    -2.516     -1.1084     1.7099    -2.4653     3.291\n",
      "  1.3248    -0.38372   -1.2117    -1.8521    -1.8656    -2.0355\n",
      "  1.5353     0.721      0.32526    0.55301   -1.9602     0.18979\n",
      " -1.7253     2.3578     1.1921     0.02616   -0.75039   -0.41764\n",
      "  0.47774   -2.4724    -2.5659     1.9391    -2.5002    -1.9114\n",
      " -0.76153    0.21264    2.1691    -1.0046     1.7196     2.8624\n",
      " -1.982     -1.7721    -1.5357    -0.55115   -0.71068    0.31037\n",
      " -4.8333    -0.9547     0.50668    1.4649    -2.5088    -2.2672\n",
      "  1.8745     0.40236   -1.4966    -0.95259    0.33245    1.3369\n",
      " -1.2619     2.0177     0.0058205  2.301      0.8945     1.9065\n",
      " -4.8127     2.9241    -0.010986   5.1142     1.1162    -2.2727\n",
      " -0.36372   -1.0767     2.1388     0.89246    0.76602    3.6443\n",
      " -1.1       -1.2867     1.0118    -0.88583    0.81568    0.21066\n",
      " -1.9269    -1.0552    -3.2312    -0.45024   -3.5863     2.0563\n",
      " -0.87917    1.2459     1.7494    -0.30862    2.0063    -1.7205\n",
      "  0.1514     0.85783    3.4151    -1.6183    -2.0185    -4.3598\n",
      " -0.35647   -0.8838     1.651     -0.6252     5.442      2.838\n",
      " -1.0607    -0.14265    3.502     -1.4755    -0.78159    0.68439\n",
      " -1.765      0.35102    1.5001    -0.45251   -2.7891     0.73818\n",
      "  1.0284     0.81208   -3.4684    -2.825      2.7257    -0.71383\n",
      " -0.036576   1.8022    -0.59502   -1.5045     1.7351     0.9858\n",
      " -0.18166   -0.30188    2.7633     2.462      0.51228    1.4472\n",
      "  0.18005   -0.16542    3.9819    -0.77608   -1.5743    -1.8987\n",
      " -1.5588    -0.30315   -0.37015    1.4542     1.0928     5.7626\n",
      " -0.33156    2.4605    -2.9048     0.37444    2.7696    -0.55158\n",
      " -3.8531     3.3329    -2.9678     1.91       0.34805   -3.2526\n",
      "  0.41625   -3.0711    -1.6431     1.4027     0.18811    2.135\n",
      " -2.7562     0.64648   -0.67172   -0.9426    -1.6983    -0.29299\n",
      " -1.2358    -0.8671    -1.505     -1.4582    -0.96021   -1.0695\n",
      "  0.98906   -0.31291    1.0298    -0.20764    0.1178    -0.28929\n",
      " -0.96931    1.1361    -0.49876   -1.4803     1.785     -1.0014\n",
      " -0.77869    0.80452    0.45709    2.7993    -0.2267     4.3011\n",
      " -0.89039   -0.30694   -2.4102    -2.6153     1.5076     2.1778\n",
      "  0.73384    2.5682     0.5536     2.0752    -0.41399   -1.5439\n",
      " -3.2161    -1.8556    -0.098283  -0.46698    3.1329     0.54761\n",
      "  1.3459    -1.7844    -0.73651    0.92371   -0.99422    1.7535\n",
      " -0.18118    1.0898     0.57058   -1.9208     3.7281     3.5387\n",
      " -0.58065   -0.047505  -0.03113    0.53139    0.098344  -1.3976\n",
      "  0.82334   -0.76732   -1.8851    -3.0228     2.4437    -2.1144\n",
      "  0.93989   -2.0234    -1.0524     1.4858     0.2706    -2.3347\n",
      " -0.93308    3.5771     1.4376     1.6913    -0.65219   -0.82584\n",
      "  3.1983    -1.8013    -1.1897     5.3266    -1.0508    -0.42526\n",
      " -3.861     -0.86484    1.6431     1.0666     0.35727   -0.3074\n",
      " -0.98946   -0.25722    0.15155    0.73672   -1.3302     1.3975\n",
      " -0.6114     0.6409    -0.84173   -2.5469    -2.2268    -2.638\n",
      "  2.1486     2.554      2.4986     2.0411     0.11555    0.13828\n",
      "  1.0179    -1.3827     0.72395    3.848     -2.2304    -1.9485   ]\n"
     ]
    }
   ],
   "source": [
    "banana_vector = nlp(u'Banana').vector \n",
    "print(banana_vector) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9477d5e-2081-4ca0-b743-67f0d7592c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog          1   18.24785041809082     0\n",
      "cat          1   48.36005401611328     0\n",
      "banana       1  32.384002685546875     0\n",
      "afskfsd      0                 0.0     1\n"
     ]
    }
   ],
   "source": [
    "tokens = nlp(\"dog cat banana afskfsd\") \n",
    "for token in tokens:     \n",
    "    print(f\"{token.text:{10}} {token.has_vector:{3}}\" f\"{token.vector_norm:{20}} {token.is_oov:{5}}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88eb9a9-43d2-4de6-9fb7-f3f9db303dda",
   "metadata": {},
   "source": [
    "#### Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "557ed948-5cdc-426d-8836-55d0f9e509db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-lg==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl (400.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.7/400.7 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9044915e-b310-4601-88cd-e65fb9347605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting de-core-news-md==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_md-3.8.0/de_core_news_md-3.8.0-py3-none-any.whl (44.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('de_core_news_md')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download de_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f37a7f7-3697-4e49-a363-80824faba74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ähnliche Wörter: ['Hrn.', 'Frau', 'König', 'Fam.']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "import spacy \n",
    "\n",
    "#nlp=spacy.load(\"en_core_web_lg\") \n",
    "nlp = spacy.load(\"de_core_news_md\")\n",
    "\n",
    "king=nlp.vocab['king'].vector \n",
    "man=nlp.vocab['man'].vector \n",
    "woman=nlp.vocab['woman'].vector # Wortvektoren verrechnen \n",
    "\n",
    "snake = nlp.vocab['snake'].vector\n",
    "lizard = nlp.vocab['lizard'].vector\n",
    "legs = nlp.vocab['legs'].vector\n",
    "\n",
    "koenig=nlp.vocab['König'].vector \n",
    "mann=nlp.vocab['Mann'].vector \n",
    "frau=nlp.vocab['Frau'].vector \n",
    "\n",
    "#new_vector = king - man + woman # Vokabular durchlaufen und ähnliche Wörter mit den ähnlichsten Vektoren finden. Ähnlichkeit wird durch Schwellenwert definiert. \n",
    "#new_vector = snake + legs - lizard\n",
    "new_vector = koenig - mann + frau\n",
    "\n",
    "similar_words = [] \n",
    "\n",
    "for token in nlp.vocab:     # Stoppwörter überspringen     \n",
    "    \n",
    "    if not token.has_vector:         \n",
    "        continue # Ähnlichkeit zwischen dem gegebenen Vektor und dem jeweiligen Token-Vektor ermitteln     \n",
    "    \n",
    "    similarity = cosine_similarity(new_vector.reshape(1,-1), token.vector.reshape(1,-1))     # > Schwellwert, dann hinzufügen     \n",
    "        \n",
    "    if similarity > 0.5:           \n",
    "        similar_words.append(token.text) \n",
    "            \n",
    "            \n",
    "print(\"Ähnliche Wörter:\", similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aafe9a8-5ac1-4462-a98b-2d2ea7b2b98f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
